{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as graph\n",
    "import seaborn as sns\n",
    "\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from rosey.helpers import vec_to_array\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import keras\n",
    "import keras.losses as klosses\n",
    "import keras.optimizers as kopt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "# %env KERAS_BACKEND=theano\n",
    "# %env THEANO_FLAGS=device=cuda3,floatX=float32,optimizer=fast_run\n",
    "\n",
    "graph.style.use('fivethirtyeight')\n",
    "\n",
    "def plot_number(xi, yi=''):\n",
    "    graph.figure(figsize=(1, 1))\n",
    "    graph.title('{}'.format(yi))\n",
    "    graph.imshow(xi.reshape(28, 28), cmap='Greys')\n",
    "    graph.xticks([])\n",
    "    graph.yticks([])\n",
    "    graph.grid(False)\n",
    "    graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/digit-recognizer/train.csv')\n",
    "\n",
    "y = df.pop('label')\n",
    "x = df.values\n",
    "x = MinMaxScaler().fit_transform(x)\n",
    "print(y.shape, x.shape)\n",
    "\n",
    "y_train, y_test, x_train, x_test = train_test_split(y, x, test_size=0.25)\n",
    "_ = [print(a.shape) for a in (y_train, y_test, x_train, x_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_number(x[0, :])\n",
    "plot_number(x[39370, :])\n",
    "plot_number(x[17521, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple Autoencoder\n",
    "input_layer = Input(shape=(x.shape[1],))\n",
    "\n",
    "encoder_layer = Dense(100, activation='elu')(input_layer)  # Bottleneck\n",
    "\n",
    "output_layer = Dense(x.shape[1], activation='sigmoid')(encoder_layer)\n",
    "\n",
    "# Create models\n",
    "autoencoder = Model(input_layer, output_layer)\n",
    "encoder = Model(input_layer, encoder_layer)\n",
    "\n",
    "display(autoencoder.summary())\n",
    "\n",
    "# Compile\n",
    "autoencoder.compile(\n",
    "    loss=klosses.binary_crossentropy,\n",
    "    optimizer=kopt.RMSprop(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before Fitting!\n",
    "for i in range(3):\n",
    "    number = vec_to_array(x_train[i, :]).T\n",
    "\n",
    "    plot_number(number)\n",
    "    plot_number(autoencoder.predict(number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Fit model! (n*100) epochs\n",
    "for i in range(5):\n",
    "    print(f'Epoch Cycle {i+1}')\n",
    "    \n",
    "    # Check fit\n",
    "    for i_img in range(5):\n",
    "        number_i = vec_to_array(x_train[i_img, :]).T\n",
    "        \n",
    "        plot_number(number_i, 'in')\n",
    "        plot_number(autoencoder.predict(number_i), 'out')\n",
    "    \n",
    "    # Train\n",
    "    hist = autoencoder.fit(\n",
    "        x_train, x_train,\n",
    "        epochs=100, validation_data=(x_test, x_test), batch_size=4096,\n",
    "        callbacks=[\n",
    "            EarlyStopping(monitor='val_loss', patience=15),\n",
    "            ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.5, min_lr=1e-6, verbose=1),\n",
    "            # TQDMCallback(),\n",
    "            ModelCheckpoint('data/model.ckp', monitor='val_loss', save_best_only=True)\n",
    "        ],\n",
    "        shuffle=True,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Summary of performance\n",
    "    graph.plot(hist.history['loss'], label='Train Score')\n",
    "    graph.plot(hist.history['val_loss'], label='Validation Score')\n",
    "    graph.legend()\n",
    "    graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After Fitting!\n",
    "for i in range(3):\n",
    "    number = vec_to_array(x_train[i, :]).T\n",
    "\n",
    "    plot_number(number)\n",
    "    plot_number(autoencoder.predict(number))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_number = vec_to_array(x_test[1013, :]).T\n",
    "\n",
    "plot_number(new_number)\n",
    "\n",
    "sns.heatmap(new_number.reshape((28, 28)), square=True)\n",
    "graph.show()\n",
    "\n",
    "print('Representation')\n",
    "sns.heatmap(encoder.predict(new_number))\n",
    "graph.show()\n",
    "\n",
    "print('')\n",
    "plot_number(autoencoder.predict(new_number))\n",
    "\n",
    "sns.heatmap(autoencoder.predict(new_number).reshape((28, 28)), square=True)\n",
    "graph.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test set fits!\n",
    "for i in range(10):\n",
    "    number = vec_to_array(x_test[i, :]).T\n",
    "\n",
    "    plot_number(number, 'Input')\n",
    "    plot_number(autoencoder.predict(number), 'Output')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Numbers\n",
    "\n",
    "I'm going to use the representations as the features for predicting which number is being represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L stands for latent representation\n",
    "l_train, l_test = [encoder.predict(data) for data in (x_train, x_test)]\n",
    "\n",
    "print(l_train.shape, l_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "logit = LogisticRegressionCV(Cs=25, cv=2, penalty='l2', n_jobs=-1, multi_class='multinomial')\n",
    "logit.fit(l_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "gbm = XGBClassifier(n_estimators=2000, n_jobs=cpu_count())\n",
    "gbm.fit(l_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scores\n",
    "print(f'Raw    = {logit.score(l_test, y_test)}')\n",
    "print(f'XGB    = {gbm.score(l_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
